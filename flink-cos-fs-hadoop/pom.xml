<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>flink-cos-fs</artifactId>
        <groupId>com.qcloud.cos</groupId>
        <version>1.10.0-0.2.2</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>flink-cos-fs-hadoop</artifactId>
    <name>Flink : FileSystems : COS FS Hadoop</name>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
        <!-- hadoop.shading.prefix 必须跟 hadoop shaded module 中的-->
        <hadoop.shading.prefix>org.apache.flink.fs.shaded.hadoop3</hadoop.shading.prefix>
        <cos.shading.prefix>org.apache.flink.fs.coshadoop</cos.shading.prefix>
        <maven.deploy.skip>false</maven.deploy.skip>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-core</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>com.qcloud.cos</groupId>
            <artifactId>flink-cos-fs-base</artifactId>
            <version>${project.version}</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <!-- NOTE：这里是适配了一下 cos_api-bundle:5.6.69 里面的 shade 插件版本，否则会报错-->
                <version>3.2.4</version>
                <executions>
                    <execution>
                        <id>shade-flink</id>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <shadeTestJar>false</shadeTestJar>
                            <artifactSet>
                                <includes>
                                    <include>*:*</include>
                                </includes>
                            </artifactSet>
                            <relocations>
                                <!-- TODO: merge bucket network load org.apache.hadoop.* relate class,
                                if shaded relate class will cause the ClassNotFound, but if not shaded
                                must keep not conflict with local hadoop version.
                                if shade org.apache.hadoop and need use ranger client must set:
                                fs.cosn.ranger.plugin.client.impl: org.apache.flink.fs.shaded.hadoop3.org.apache.hadoop.
                                fs.cosn.ranger.client.RangerQcloudObjectStorageClientImpl

                                todo: there may be a better way to solve this problem such like control the ofs java sdk
                                load way, to direct load shade plugins so that can always shade it.
                                if you need shade hadoop and use ranger at same time, it seems not work for now.
                                 -->
                                <relocation>
                                    <pattern>org.apache.hadoop</pattern>
                                    <shadedPattern>${hadoop.shading.prefix}.org.apache.hadoop</shadedPattern>
                                    <excludes>
                                        <exclude>org.apache.hadoop.fs.cosn.ranger.protocol.*</exclude>
                                        <exclude>org/apache/flink/fs/coshadoop/Constants.class</exclude>
                                    </excludes>
                                </relocation>

                                <!-- used by ranger to load provider class, which must test for other provider-->
                                <!--
                                <relocation>
                                    <pattern>org.apache.hadoop.fs.auth</pattern>
                                    <shadedPattern>${hadoop.shading.prefix}.org.apache.hadoop.fs.auth</shadedPattern>
                                </relocation>
                                -->

                                <relocation>
                                    <pattern>org.apache.commons</pattern>
                                    <shadedPattern>${hadoop.shading.prefix}.org.apache.commons</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>com.google.common</pattern>
                                    <shadedPattern>${hadoop.shading.prefix}.com.google.common</shadedPattern>
                                </relocation>

                                <!-- todo no need on emr -->
                                <relocation>
                                    <pattern>com.qcloud</pattern>
                                    <shadedPattern>${cos.shading.prefix}.shaded.com.qcloud</shadedPattern>
                                    <excludes>
                                        <!-- avoid relocate fs lock class cause network can not load real jar-->
                                        <exclude>com.qcloud.chdfs.**</exclude>
                                    </excludes>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.flink.runtime.fs.hdfs</pattern>
                                    <shadedPattern>${cos.shading.prefix}.common</shadedPattern>
                                </relocation>

                                <relocation>
                                    <pattern>org.apache.flink.runtime.util</pattern>
                                    <shadedPattern>${cos.shading.prefix}.common</shadedPattern>
                                </relocation>
                            </relocations>
<!--
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>org/apache/hadoop/**</exclude>
                                        <exclude>com/qcloud/**</exclude>
                                    </excludes>
                                </filter>
                            </filters>
-->
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>